{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:32:45.430097Z",
     "start_time": "2020-06-22T11:32:31.037920Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:33:15.278101Z",
     "start_time": "2020-06-22T11:33:15.271099Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:33:35.336286Z",
     "start_time": "2020-06-22T11:33:31.297245Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg = models.vgg16().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:33:44.430371Z",
     "start_time": "2020-06-22T11:33:43.291362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 244, 244]           1,792\n",
      "              ReLU-2         [-1, 64, 244, 244]               0\n",
      "            Conv2d-3         [-1, 64, 244, 244]          36,928\n",
      "              ReLU-4         [-1, 64, 244, 244]               0\n",
      "         MaxPool2d-5         [-1, 64, 122, 122]               0\n",
      "            Conv2d-6        [-1, 128, 122, 122]          73,856\n",
      "              ReLU-7        [-1, 128, 122, 122]               0\n",
      "            Conv2d-8        [-1, 128, 122, 122]         147,584\n",
      "              ReLU-9        [-1, 128, 122, 122]               0\n",
      "        MaxPool2d-10          [-1, 128, 61, 61]               0\n",
      "           Conv2d-11          [-1, 256, 61, 61]         295,168\n",
      "             ReLU-12          [-1, 256, 61, 61]               0\n",
      "           Conv2d-13          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-14          [-1, 256, 61, 61]               0\n",
      "           Conv2d-15          [-1, 256, 61, 61]         590,080\n",
      "             ReLU-16          [-1, 256, 61, 61]               0\n",
      "        MaxPool2d-17          [-1, 256, 30, 30]               0\n",
      "           Conv2d-18          [-1, 512, 30, 30]       1,180,160\n",
      "             ReLU-19          [-1, 512, 30, 30]               0\n",
      "           Conv2d-20          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-21          [-1, 512, 30, 30]               0\n",
      "           Conv2d-22          [-1, 512, 30, 30]       2,359,808\n",
      "             ReLU-23          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-24          [-1, 512, 15, 15]               0\n",
      "           Conv2d-25          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-26          [-1, 512, 15, 15]               0\n",
      "           Conv2d-27          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-28          [-1, 512, 15, 15]               0\n",
      "           Conv2d-29          [-1, 512, 15, 15]       2,359,808\n",
      "             ReLU-30          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
      "           Linear-33                 [-1, 4096]     102,764,544\n",
      "             ReLU-34                 [-1, 4096]               0\n",
      "          Dropout-35                 [-1, 4096]               0\n",
      "           Linear-36                 [-1, 4096]      16,781,312\n",
      "             ReLU-37                 [-1, 4096]               0\n",
      "          Dropout-38                 [-1, 4096]               0\n",
      "           Linear-39                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 258.51\n",
      "Params size (MB): 527.79\n",
      "Estimated Total Size (MB): 786.98\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(vgg, input_size = (3,244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. multi input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:37:08.086807Z",
     "start_time": "2020-06-22T11:37:08.043805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 1, 16, 16]              10\n",
      "              ReLU-2            [-1, 1, 16, 16]               0\n",
      "            Conv2d-3            [-1, 1, 28, 28]              10\n",
      "              ReLU-4            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.77\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class SimpleConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleConv, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x, y):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.features(y)\n",
    "        return x1, x2\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleConv().to(device)\n",
    "summary(model, [(1, 16, 16), (1, 28, 28)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. multi input + model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:37:52.432799Z",
     "start_time": "2020-06-22T11:37:52.412810Z"
    }
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*100*100, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 5))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        print(output.shape)   #torch.Size([2, 8, 100, 100])\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        print(output.shape)   #torch.Size([2, 80000])\n",
    "        output = self.fc1(output)\n",
    "        print(output.shape)   #torch.Size([2, 5])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:38:01.146880Z",
     "start_time": "2020-06-22T11:38:00.753883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 100, 100])\n",
      "torch.Size([2, 80000])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 8, 100, 100])\n",
      "torch.Size([2, 80000])\n",
      "torch.Size([2, 5])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ReflectionPad2d-1          [-1, 1, 102, 102]               0\n",
      "            Conv2d-2          [-1, 4, 100, 100]              40\n",
      "              ReLU-3          [-1, 4, 100, 100]               0\n",
      "       BatchNorm2d-4          [-1, 4, 100, 100]               8\n",
      "   ReflectionPad2d-5          [-1, 4, 102, 102]               0\n",
      "            Conv2d-6          [-1, 8, 100, 100]             296\n",
      "              ReLU-7          [-1, 8, 100, 100]               0\n",
      "       BatchNorm2d-8          [-1, 8, 100, 100]              16\n",
      "   ReflectionPad2d-9          [-1, 8, 102, 102]               0\n",
      "           Conv2d-10          [-1, 8, 100, 100]             584\n",
      "             ReLU-11          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-12          [-1, 8, 100, 100]              16\n",
      "           Linear-13                  [-1, 500]      40,000,500\n",
      "             ReLU-14                  [-1, 500]               0\n",
      "           Linear-15                  [-1, 500]         250,500\n",
      "             ReLU-16                  [-1, 500]               0\n",
      "           Linear-17                    [-1, 5]           2,505\n",
      "  ReflectionPad2d-18          [-1, 1, 102, 102]               0\n",
      "           Conv2d-19          [-1, 4, 100, 100]              40\n",
      "             ReLU-20          [-1, 4, 100, 100]               0\n",
      "      BatchNorm2d-21          [-1, 4, 100, 100]               8\n",
      "  ReflectionPad2d-22          [-1, 4, 102, 102]               0\n",
      "           Conv2d-23          [-1, 8, 100, 100]             296\n",
      "             ReLU-24          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-25          [-1, 8, 100, 100]              16\n",
      "  ReflectionPad2d-26          [-1, 8, 102, 102]               0\n",
      "           Conv2d-27          [-1, 8, 100, 100]             584\n",
      "             ReLU-28          [-1, 8, 100, 100]               0\n",
      "      BatchNorm2d-29          [-1, 8, 100, 100]              16\n",
      "           Linear-30                  [-1, 500]      40,000,500\n",
      "             ReLU-31                  [-1, 500]               0\n",
      "           Linear-32                  [-1, 500]         250,500\n",
      "             ReLU-33                  [-1, 500]               0\n",
      "           Linear-34                    [-1, 5]           2,505\n",
      "================================================================\n",
      "Total params: 80,508,930\n",
      "Trainable params: 80,508,930\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 381.47\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 307.12\n",
      "Estimated Total Size (MB): 699.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SiameseNetwork().to(device)\n",
    "summary(model, [(1, 100, 100), (1, 100, 100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Resnet + multi input + class model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:39:38.151841Z",
     "start_time": "2020-06-22T11:39:37.932843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "print(num_ftrs)\n",
    "# 여기서 각 출력 샘플의 크기는 2로 설정합니다.\n",
    "# 또는, nn.Linear(num_ftrs, len (class_names))로 일반화할 수 있습니다.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:39:52.067969Z",
     "start_time": "2020-06-22T11:39:51.682970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 119.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model_ft, input_size = (3, 244, 244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:41:20.216801Z",
     "start_time": "2020-06-22T11:41:20.211802Z"
    }
   },
   "outputs": [],
   "source": [
    "def SiameseNetwork(original_model):\n",
    "    if original_model == 'resnet18':\n",
    "        model = models.resnet18(pretrained=False)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        # 여기서 각 출력 샘플의 크기는 2로 설정합니다.\n",
    "        # 또는, nn.Linear(num_ftrs, len (class_names))로 일반화할 수 있습니다.\n",
    "        model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:41:21.430808Z",
     "start_time": "2020-06-22T11:41:20.949810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,177,538\n",
      "Trainable params: 11,177,538\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.68\n",
      "Forward/backward pass size (MB): 76.08\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 119.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "original_model = 'resnet18'\n",
    "model = SiameseNetwork(original_model)\n",
    "summary(model, (3, 244,244))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:42:57.687714Z",
     "start_time": "2020-06-22T11:42:57.670717Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*100*100, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 5))\n",
    "        \n",
    "        self.Network = nn.Sequential(\n",
    "            models.resnet18(pretrained=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1000, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.Network(x)\n",
    "#         output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "#         print(output.shape)\n",
    "#         output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:43:18.218907Z",
     "start_time": "2020-06-22T11:43:17.118895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 122, 122]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 122, 122]             128\n",
      "              ReLU-3         [-1, 64, 122, 122]               0\n",
      "         MaxPool2d-4           [-1, 64, 61, 61]               0\n",
      "            Conv2d-5           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 61, 61]             128\n",
      "              ReLU-7           [-1, 64, 61, 61]               0\n",
      "            Conv2d-8           [-1, 64, 61, 61]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 61, 61]             128\n",
      "             ReLU-10           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-11           [-1, 64, 61, 61]               0\n",
      "           Conv2d-12           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 61, 61]             128\n",
      "             ReLU-14           [-1, 64, 61, 61]               0\n",
      "           Conv2d-15           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 61, 61]             128\n",
      "             ReLU-17           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-18           [-1, 64, 61, 61]               0\n",
      "           Conv2d-19          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 31, 31]             256\n",
      "             ReLU-21          [-1, 128, 31, 31]               0\n",
      "           Conv2d-22          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 31, 31]             256\n",
      "           Conv2d-24          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 31, 31]             256\n",
      "             ReLU-26          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-27          [-1, 128, 31, 31]               0\n",
      "           Conv2d-28          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 31, 31]             256\n",
      "             ReLU-30          [-1, 128, 31, 31]               0\n",
      "           Conv2d-31          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 31, 31]             256\n",
      "             ReLU-33          [-1, 128, 31, 31]               0\n",
      "       BasicBlock-34          [-1, 128, 31, 31]               0\n",
      "           Conv2d-35          [-1, 256, 16, 16]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 16, 16]             512\n",
      "             ReLU-37          [-1, 256, 16, 16]               0\n",
      "           Conv2d-38          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 16, 16]             512\n",
      "           Conv2d-40          [-1, 256, 16, 16]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 16, 16]             512\n",
      "             ReLU-42          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-43          [-1, 256, 16, 16]               0\n",
      "           Conv2d-44          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 16, 16]             512\n",
      "             ReLU-46          [-1, 256, 16, 16]               0\n",
      "           Conv2d-47          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 16, 16]             512\n",
      "             ReLU-49          [-1, 256, 16, 16]               0\n",
      "       BasicBlock-50          [-1, 256, 16, 16]               0\n",
      "           Conv2d-51            [-1, 512, 8, 8]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-53            [-1, 512, 8, 8]               0\n",
      "           Conv2d-54            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 8, 8]           1,024\n",
      "           Conv2d-56            [-1, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-58            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-59            [-1, 512, 8, 8]               0\n",
      "           Conv2d-60            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-62            [-1, 512, 8, 8]               0\n",
      "           Conv2d-63            [-1, 512, 8, 8]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 8, 8]           1,024\n",
      "             ReLU-65            [-1, 512, 8, 8]               0\n",
      "       BasicBlock-66            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "           ResNet-69                 [-1, 1000]               0\n",
      "             ReLU-70                 [-1, 1000]               0\n",
      "          Dropout-71                 [-1, 1000]               0\n",
      "           Linear-72                    [-1, 5]           5,005\n",
      "             ReLU-73                    [-1, 5]               0\n",
      "          Dropout-74                    [-1, 5]               0\n",
      "           Conv2d-75         [-1, 64, 122, 122]           9,408\n",
      "      BatchNorm2d-76         [-1, 64, 122, 122]             128\n",
      "             ReLU-77         [-1, 64, 122, 122]               0\n",
      "        MaxPool2d-78           [-1, 64, 61, 61]               0\n",
      "           Conv2d-79           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-80           [-1, 64, 61, 61]             128\n",
      "             ReLU-81           [-1, 64, 61, 61]               0\n",
      "           Conv2d-82           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-83           [-1, 64, 61, 61]             128\n",
      "             ReLU-84           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-85           [-1, 64, 61, 61]               0\n",
      "           Conv2d-86           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-87           [-1, 64, 61, 61]             128\n",
      "             ReLU-88           [-1, 64, 61, 61]               0\n",
      "           Conv2d-89           [-1, 64, 61, 61]          36,864\n",
      "      BatchNorm2d-90           [-1, 64, 61, 61]             128\n",
      "             ReLU-91           [-1, 64, 61, 61]               0\n",
      "       BasicBlock-92           [-1, 64, 61, 61]               0\n",
      "           Conv2d-93          [-1, 128, 31, 31]          73,728\n",
      "      BatchNorm2d-94          [-1, 128, 31, 31]             256\n",
      "             ReLU-95          [-1, 128, 31, 31]               0\n",
      "           Conv2d-96          [-1, 128, 31, 31]         147,456\n",
      "      BatchNorm2d-97          [-1, 128, 31, 31]             256\n",
      "           Conv2d-98          [-1, 128, 31, 31]           8,192\n",
      "      BatchNorm2d-99          [-1, 128, 31, 31]             256\n",
      "            ReLU-100          [-1, 128, 31, 31]               0\n",
      "      BasicBlock-101          [-1, 128, 31, 31]               0\n",
      "          Conv2d-102          [-1, 128, 31, 31]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 31, 31]             256\n",
      "            ReLU-104          [-1, 128, 31, 31]               0\n",
      "          Conv2d-105          [-1, 128, 31, 31]         147,456\n",
      "     BatchNorm2d-106          [-1, 128, 31, 31]             256\n",
      "            ReLU-107          [-1, 128, 31, 31]               0\n",
      "      BasicBlock-108          [-1, 128, 31, 31]               0\n",
      "          Conv2d-109          [-1, 256, 16, 16]         294,912\n",
      "     BatchNorm2d-110          [-1, 256, 16, 16]             512\n",
      "            ReLU-111          [-1, 256, 16, 16]               0\n",
      "          Conv2d-112          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-113          [-1, 256, 16, 16]             512\n",
      "          Conv2d-114          [-1, 256, 16, 16]          32,768\n",
      "     BatchNorm2d-115          [-1, 256, 16, 16]             512\n",
      "            ReLU-116          [-1, 256, 16, 16]               0\n",
      "      BasicBlock-117          [-1, 256, 16, 16]               0\n",
      "          Conv2d-118          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-119          [-1, 256, 16, 16]             512\n",
      "            ReLU-120          [-1, 256, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "      BasicBlock-124          [-1, 256, 16, 16]               0\n",
      "          Conv2d-125            [-1, 512, 8, 8]       1,179,648\n",
      "     BatchNorm2d-126            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-127            [-1, 512, 8, 8]               0\n",
      "          Conv2d-128            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-129            [-1, 512, 8, 8]           1,024\n",
      "          Conv2d-130            [-1, 512, 8, 8]         131,072\n",
      "     BatchNorm2d-131            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-132            [-1, 512, 8, 8]               0\n",
      "      BasicBlock-133            [-1, 512, 8, 8]               0\n",
      "          Conv2d-134            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-135            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-136            [-1, 512, 8, 8]               0\n",
      "          Conv2d-137            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-138            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-139            [-1, 512, 8, 8]               0\n",
      "      BasicBlock-140            [-1, 512, 8, 8]               0\n",
      "AdaptiveAvgPool2d-141            [-1, 512, 1, 1]               0\n",
      "          Linear-142                 [-1, 1000]         513,000\n",
      "          ResNet-143                 [-1, 1000]               0\n",
      "            ReLU-144                 [-1, 1000]               0\n",
      "         Dropout-145                 [-1, 1000]               0\n",
      "          Linear-146                    [-1, 5]           5,005\n",
      "            ReLU-147                    [-1, 5]               0\n",
      "         Dropout-148                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 23,389,034\n",
      "Trainable params: 23,389,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7003.96\n",
      "Forward/backward pass size (MB): 152.21\n",
      "Params size (MB): 89.22\n",
      "Estimated Total Size (MB): 7245.40\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SiameseNetwork().to(device)\n",
    "summary(model, input_size = [(3,244,244),(3,244,244)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:48:59.219108Z",
     "start_time": "2020-06-22T11:48:59.083148Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:48:59.913120Z",
     "start_time": "2020-06-22T11:48:59.905124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=False)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:03.562160Z",
     "start_time": "2020-06-22T11:49:03.555154Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier[1].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:25.831367Z",
     "start_time": "2020-06-22T11:49:25.740371Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    models.mobilenet_v2(pretrained=False),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(1000, 5),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:34.659444Z",
     "start_time": "2020-06-22T11:49:34.250448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "     MobileNetV2-159                 [-1, 1000]               0\n",
      "            ReLU-160                 [-1, 1000]               0\n",
      "         Dropout-161                 [-1, 1000]               0\n",
      "          Linear-162                    [-1, 5]           5,005\n",
      "            ReLU-163                    [-1, 5]               0\n",
      "         Dropout-164                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 3,509,877\n",
      "Trainable params: 3,509,877\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.89\n",
      "Params size (MB): 13.39\n",
      "Estimated Total Size (MB): 166.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:39.603493Z",
     "start_time": "2020-06-22T11:49:39.583493Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(8, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*100*100, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(500, 5))\n",
    "        \n",
    "        self.Network = nn.Sequential(\n",
    "            models.mobilenet_v2(pretrained=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1000, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.Network(x)\n",
    "        print(output.shape)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        print(output.shape)\n",
    "#         output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:41.590510Z",
     "start_time": "2020-06-22T11:49:41.201515Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = SiameseNetwork().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T11:49:43.304526Z",
     "start_time": "2020-06-22T11:49:42.433517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "torch.Size([2, 5])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 122, 122]             864\n",
      "       BatchNorm2d-2         [-1, 32, 122, 122]              64\n",
      "             ReLU6-3         [-1, 32, 122, 122]               0\n",
      "            Conv2d-4         [-1, 32, 122, 122]             288\n",
      "       BatchNorm2d-5         [-1, 32, 122, 122]              64\n",
      "             ReLU6-6         [-1, 32, 122, 122]               0\n",
      "            Conv2d-7         [-1, 16, 122, 122]             512\n",
      "       BatchNorm2d-8         [-1, 16, 122, 122]              32\n",
      "  InvertedResidual-9         [-1, 16, 122, 122]               0\n",
      "           Conv2d-10         [-1, 96, 122, 122]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 122, 122]             192\n",
      "            ReLU6-12         [-1, 96, 122, 122]               0\n",
      "           Conv2d-13           [-1, 96, 61, 61]             864\n",
      "      BatchNorm2d-14           [-1, 96, 61, 61]             192\n",
      "            ReLU6-15           [-1, 96, 61, 61]               0\n",
      "           Conv2d-16           [-1, 24, 61, 61]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-18           [-1, 24, 61, 61]               0\n",
      "           Conv2d-19          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 61, 61]             288\n",
      "            ReLU6-21          [-1, 144, 61, 61]               0\n",
      "           Conv2d-22          [-1, 144, 61, 61]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 61, 61]             288\n",
      "            ReLU6-24          [-1, 144, 61, 61]               0\n",
      "           Conv2d-25           [-1, 24, 61, 61]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 61, 61]              48\n",
      " InvertedResidual-27           [-1, 24, 61, 61]               0\n",
      "           Conv2d-28          [-1, 144, 61, 61]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 61, 61]             288\n",
      "            ReLU6-30          [-1, 144, 61, 61]               0\n",
      "           Conv2d-31          [-1, 144, 31, 31]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 31, 31]             288\n",
      "            ReLU6-33          [-1, 144, 31, 31]               0\n",
      "           Conv2d-34           [-1, 32, 31, 31]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-36           [-1, 32, 31, 31]               0\n",
      "           Conv2d-37          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 31, 31]             384\n",
      "            ReLU6-39          [-1, 192, 31, 31]               0\n",
      "           Conv2d-40          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 31, 31]             384\n",
      "            ReLU6-42          [-1, 192, 31, 31]               0\n",
      "           Conv2d-43           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-45           [-1, 32, 31, 31]               0\n",
      "           Conv2d-46          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 31, 31]             384\n",
      "            ReLU6-48          [-1, 192, 31, 31]               0\n",
      "           Conv2d-49          [-1, 192, 31, 31]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 31, 31]             384\n",
      "            ReLU6-51          [-1, 192, 31, 31]               0\n",
      "           Conv2d-52           [-1, 32, 31, 31]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 31, 31]              64\n",
      " InvertedResidual-54           [-1, 32, 31, 31]               0\n",
      "           Conv2d-55          [-1, 192, 31, 31]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 31, 31]             384\n",
      "            ReLU6-57          [-1, 192, 31, 31]               0\n",
      "           Conv2d-58          [-1, 192, 16, 16]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 16, 16]             384\n",
      "            ReLU6-60          [-1, 192, 16, 16]               0\n",
      "           Conv2d-61           [-1, 64, 16, 16]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-63           [-1, 64, 16, 16]               0\n",
      "           Conv2d-64          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 16, 16]             768\n",
      "            ReLU6-66          [-1, 384, 16, 16]               0\n",
      "           Conv2d-67          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 16, 16]             768\n",
      "            ReLU6-69          [-1, 384, 16, 16]               0\n",
      "           Conv2d-70           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-72           [-1, 64, 16, 16]               0\n",
      "           Conv2d-73          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 16, 16]             768\n",
      "            ReLU6-75          [-1, 384, 16, 16]               0\n",
      "           Conv2d-76          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 16, 16]             768\n",
      "            ReLU6-78          [-1, 384, 16, 16]               0\n",
      "           Conv2d-79           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-81           [-1, 64, 16, 16]               0\n",
      "           Conv2d-82          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 16, 16]             768\n",
      "            ReLU6-84          [-1, 384, 16, 16]               0\n",
      "           Conv2d-85          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 16, 16]             768\n",
      "            ReLU6-87          [-1, 384, 16, 16]               0\n",
      "           Conv2d-88           [-1, 64, 16, 16]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 16, 16]             128\n",
      " InvertedResidual-90           [-1, 64, 16, 16]               0\n",
      "           Conv2d-91          [-1, 384, 16, 16]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 16, 16]             768\n",
      "            ReLU6-93          [-1, 384, 16, 16]               0\n",
      "           Conv2d-94          [-1, 384, 16, 16]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 16, 16]             768\n",
      "            ReLU6-96          [-1, 384, 16, 16]               0\n",
      "           Conv2d-97           [-1, 96, 16, 16]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 16, 16]             192\n",
      " InvertedResidual-99           [-1, 96, 16, 16]               0\n",
      "          Conv2d-100          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-102          [-1, 576, 16, 16]               0\n",
      "          Conv2d-103          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-105          [-1, 576, 16, 16]               0\n",
      "          Conv2d-106           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-108           [-1, 96, 16, 16]               0\n",
      "          Conv2d-109          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-111          [-1, 576, 16, 16]               0\n",
      "          Conv2d-112          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-114          [-1, 576, 16, 16]               0\n",
      "          Conv2d-115           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-117           [-1, 96, 16, 16]               0\n",
      "          Conv2d-118          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-120          [-1, 576, 16, 16]               0\n",
      "          Conv2d-121            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-123            [-1, 576, 8, 8]               0\n",
      "          Conv2d-124            [-1, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-126            [-1, 160, 8, 8]               0\n",
      "          Conv2d-127            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-129            [-1, 960, 8, 8]               0\n",
      "          Conv2d-130            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-132            [-1, 960, 8, 8]               0\n",
      "          Conv2d-133            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-135            [-1, 160, 8, 8]               0\n",
      "          Conv2d-136            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-138            [-1, 960, 8, 8]               0\n",
      "          Conv2d-139            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-141            [-1, 960, 8, 8]               0\n",
      "          Conv2d-142            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-144            [-1, 160, 8, 8]               0\n",
      "          Conv2d-145            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-147            [-1, 960, 8, 8]               0\n",
      "          Conv2d-148            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-150            [-1, 960, 8, 8]               0\n",
      "          Conv2d-151            [-1, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-153            [-1, 320, 8, 8]               0\n",
      "          Conv2d-154           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 8, 8]           2,560\n",
      "           ReLU6-156           [-1, 1280, 8, 8]               0\n",
      "         Dropout-157                 [-1, 1280]               0\n",
      "          Linear-158                 [-1, 1000]       1,281,000\n",
      "     MobileNetV2-159                 [-1, 1000]               0\n",
      "            ReLU-160                 [-1, 1000]               0\n",
      "         Dropout-161                 [-1, 1000]               0\n",
      "          Linear-162                    [-1, 5]           5,005\n",
      "            ReLU-163                    [-1, 5]               0\n",
      "         Dropout-164                    [-1, 5]               0\n",
      "          Conv2d-165         [-1, 32, 122, 122]             864\n",
      "     BatchNorm2d-166         [-1, 32, 122, 122]              64\n",
      "           ReLU6-167         [-1, 32, 122, 122]               0\n",
      "          Conv2d-168         [-1, 32, 122, 122]             288\n",
      "     BatchNorm2d-169         [-1, 32, 122, 122]              64\n",
      "           ReLU6-170         [-1, 32, 122, 122]               0\n",
      "          Conv2d-171         [-1, 16, 122, 122]             512\n",
      "     BatchNorm2d-172         [-1, 16, 122, 122]              32\n",
      "InvertedResidual-173         [-1, 16, 122, 122]               0\n",
      "          Conv2d-174         [-1, 96, 122, 122]           1,536\n",
      "     BatchNorm2d-175         [-1, 96, 122, 122]             192\n",
      "           ReLU6-176         [-1, 96, 122, 122]               0\n",
      "          Conv2d-177           [-1, 96, 61, 61]             864\n",
      "     BatchNorm2d-178           [-1, 96, 61, 61]             192\n",
      "           ReLU6-179           [-1, 96, 61, 61]               0\n",
      "          Conv2d-180           [-1, 24, 61, 61]           2,304\n",
      "     BatchNorm2d-181           [-1, 24, 61, 61]              48\n",
      "InvertedResidual-182           [-1, 24, 61, 61]               0\n",
      "          Conv2d-183          [-1, 144, 61, 61]           3,456\n",
      "     BatchNorm2d-184          [-1, 144, 61, 61]             288\n",
      "           ReLU6-185          [-1, 144, 61, 61]               0\n",
      "          Conv2d-186          [-1, 144, 61, 61]           1,296\n",
      "     BatchNorm2d-187          [-1, 144, 61, 61]             288\n",
      "           ReLU6-188          [-1, 144, 61, 61]               0\n",
      "          Conv2d-189           [-1, 24, 61, 61]           3,456\n",
      "     BatchNorm2d-190           [-1, 24, 61, 61]              48\n",
      "InvertedResidual-191           [-1, 24, 61, 61]               0\n",
      "          Conv2d-192          [-1, 144, 61, 61]           3,456\n",
      "     BatchNorm2d-193          [-1, 144, 61, 61]             288\n",
      "           ReLU6-194          [-1, 144, 61, 61]               0\n",
      "          Conv2d-195          [-1, 144, 31, 31]           1,296\n",
      "     BatchNorm2d-196          [-1, 144, 31, 31]             288\n",
      "           ReLU6-197          [-1, 144, 31, 31]               0\n",
      "          Conv2d-198           [-1, 32, 31, 31]           4,608\n",
      "     BatchNorm2d-199           [-1, 32, 31, 31]              64\n",
      "InvertedResidual-200           [-1, 32, 31, 31]               0\n",
      "          Conv2d-201          [-1, 192, 31, 31]           6,144\n",
      "     BatchNorm2d-202          [-1, 192, 31, 31]             384\n",
      "           ReLU6-203          [-1, 192, 31, 31]               0\n",
      "          Conv2d-204          [-1, 192, 31, 31]           1,728\n",
      "     BatchNorm2d-205          [-1, 192, 31, 31]             384\n",
      "           ReLU6-206          [-1, 192, 31, 31]               0\n",
      "          Conv2d-207           [-1, 32, 31, 31]           6,144\n",
      "     BatchNorm2d-208           [-1, 32, 31, 31]              64\n",
      "InvertedResidual-209           [-1, 32, 31, 31]               0\n",
      "          Conv2d-210          [-1, 192, 31, 31]           6,144\n",
      "     BatchNorm2d-211          [-1, 192, 31, 31]             384\n",
      "           ReLU6-212          [-1, 192, 31, 31]               0\n",
      "          Conv2d-213          [-1, 192, 31, 31]           1,728\n",
      "     BatchNorm2d-214          [-1, 192, 31, 31]             384\n",
      "           ReLU6-215          [-1, 192, 31, 31]               0\n",
      "          Conv2d-216           [-1, 32, 31, 31]           6,144\n",
      "     BatchNorm2d-217           [-1, 32, 31, 31]              64\n",
      "InvertedResidual-218           [-1, 32, 31, 31]               0\n",
      "          Conv2d-219          [-1, 192, 31, 31]           6,144\n",
      "     BatchNorm2d-220          [-1, 192, 31, 31]             384\n",
      "           ReLU6-221          [-1, 192, 31, 31]               0\n",
      "          Conv2d-222          [-1, 192, 16, 16]           1,728\n",
      "     BatchNorm2d-223          [-1, 192, 16, 16]             384\n",
      "           ReLU6-224          [-1, 192, 16, 16]               0\n",
      "          Conv2d-225           [-1, 64, 16, 16]          12,288\n",
      "     BatchNorm2d-226           [-1, 64, 16, 16]             128\n",
      "InvertedResidual-227           [-1, 64, 16, 16]               0\n",
      "          Conv2d-228          [-1, 384, 16, 16]          24,576\n",
      "     BatchNorm2d-229          [-1, 384, 16, 16]             768\n",
      "           ReLU6-230          [-1, 384, 16, 16]               0\n",
      "          Conv2d-231          [-1, 384, 16, 16]           3,456\n",
      "     BatchNorm2d-232          [-1, 384, 16, 16]             768\n",
      "           ReLU6-233          [-1, 384, 16, 16]               0\n",
      "          Conv2d-234           [-1, 64, 16, 16]          24,576\n",
      "     BatchNorm2d-235           [-1, 64, 16, 16]             128\n",
      "InvertedResidual-236           [-1, 64, 16, 16]               0\n",
      "          Conv2d-237          [-1, 384, 16, 16]          24,576\n",
      "     BatchNorm2d-238          [-1, 384, 16, 16]             768\n",
      "           ReLU6-239          [-1, 384, 16, 16]               0\n",
      "          Conv2d-240          [-1, 384, 16, 16]           3,456\n",
      "     BatchNorm2d-241          [-1, 384, 16, 16]             768\n",
      "           ReLU6-242          [-1, 384, 16, 16]               0\n",
      "          Conv2d-243           [-1, 64, 16, 16]          24,576\n",
      "     BatchNorm2d-244           [-1, 64, 16, 16]             128\n",
      "InvertedResidual-245           [-1, 64, 16, 16]               0\n",
      "          Conv2d-246          [-1, 384, 16, 16]          24,576\n",
      "     BatchNorm2d-247          [-1, 384, 16, 16]             768\n",
      "           ReLU6-248          [-1, 384, 16, 16]               0\n",
      "          Conv2d-249          [-1, 384, 16, 16]           3,456\n",
      "     BatchNorm2d-250          [-1, 384, 16, 16]             768\n",
      "           ReLU6-251          [-1, 384, 16, 16]               0\n",
      "          Conv2d-252           [-1, 64, 16, 16]          24,576\n",
      "     BatchNorm2d-253           [-1, 64, 16, 16]             128\n",
      "InvertedResidual-254           [-1, 64, 16, 16]               0\n",
      "          Conv2d-255          [-1, 384, 16, 16]          24,576\n",
      "     BatchNorm2d-256          [-1, 384, 16, 16]             768\n",
      "           ReLU6-257          [-1, 384, 16, 16]               0\n",
      "          Conv2d-258          [-1, 384, 16, 16]           3,456\n",
      "     BatchNorm2d-259          [-1, 384, 16, 16]             768\n",
      "           ReLU6-260          [-1, 384, 16, 16]               0\n",
      "          Conv2d-261           [-1, 96, 16, 16]          36,864\n",
      "     BatchNorm2d-262           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-263           [-1, 96, 16, 16]               0\n",
      "          Conv2d-264          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-265          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-266          [-1, 576, 16, 16]               0\n",
      "          Conv2d-267          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-268          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-269          [-1, 576, 16, 16]               0\n",
      "          Conv2d-270           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-271           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-272           [-1, 96, 16, 16]               0\n",
      "          Conv2d-273          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-274          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-275          [-1, 576, 16, 16]               0\n",
      "          Conv2d-276          [-1, 576, 16, 16]           5,184\n",
      "     BatchNorm2d-277          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-278          [-1, 576, 16, 16]               0\n",
      "          Conv2d-279           [-1, 96, 16, 16]          55,296\n",
      "     BatchNorm2d-280           [-1, 96, 16, 16]             192\n",
      "InvertedResidual-281           [-1, 96, 16, 16]               0\n",
      "          Conv2d-282          [-1, 576, 16, 16]          55,296\n",
      "     BatchNorm2d-283          [-1, 576, 16, 16]           1,152\n",
      "           ReLU6-284          [-1, 576, 16, 16]               0\n",
      "          Conv2d-285            [-1, 576, 8, 8]           5,184\n",
      "     BatchNorm2d-286            [-1, 576, 8, 8]           1,152\n",
      "           ReLU6-287            [-1, 576, 8, 8]               0\n",
      "          Conv2d-288            [-1, 160, 8, 8]          92,160\n",
      "     BatchNorm2d-289            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-290            [-1, 160, 8, 8]               0\n",
      "          Conv2d-291            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-292            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-293            [-1, 960, 8, 8]               0\n",
      "          Conv2d-294            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-295            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-296            [-1, 960, 8, 8]               0\n",
      "          Conv2d-297            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-298            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-299            [-1, 160, 8, 8]               0\n",
      "          Conv2d-300            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-301            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-302            [-1, 960, 8, 8]               0\n",
      "          Conv2d-303            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-304            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-305            [-1, 960, 8, 8]               0\n",
      "          Conv2d-306            [-1, 160, 8, 8]         153,600\n",
      "     BatchNorm2d-307            [-1, 160, 8, 8]             320\n",
      "InvertedResidual-308            [-1, 160, 8, 8]               0\n",
      "          Conv2d-309            [-1, 960, 8, 8]         153,600\n",
      "     BatchNorm2d-310            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-311            [-1, 960, 8, 8]               0\n",
      "          Conv2d-312            [-1, 960, 8, 8]           8,640\n",
      "     BatchNorm2d-313            [-1, 960, 8, 8]           1,920\n",
      "           ReLU6-314            [-1, 960, 8, 8]               0\n",
      "          Conv2d-315            [-1, 320, 8, 8]         307,200\n",
      "     BatchNorm2d-316            [-1, 320, 8, 8]             640\n",
      "InvertedResidual-317            [-1, 320, 8, 8]               0\n",
      "          Conv2d-318           [-1, 1280, 8, 8]         409,600\n",
      "     BatchNorm2d-319           [-1, 1280, 8, 8]           2,560\n",
      "           ReLU6-320           [-1, 1280, 8, 8]               0\n",
      "         Dropout-321                 [-1, 1280]               0\n",
      "          Linear-322                 [-1, 1000]       1,281,000\n",
      "     MobileNetV2-323                 [-1, 1000]               0\n",
      "            ReLU-324                 [-1, 1000]               0\n",
      "         Dropout-325                 [-1, 1000]               0\n",
      "          Linear-326                    [-1, 5]           5,005\n",
      "            ReLU-327                    [-1, 5]               0\n",
      "         Dropout-328                    [-1, 5]               0\n",
      "================================================================\n",
      "Total params: 7,019,754\n",
      "Trainable params: 7,019,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 7003.96\n",
      "Forward/backward pass size (MB): 373.93\n",
      "Params size (MB): 26.78\n",
      "Estimated Total Size (MB): 7404.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, [(3,244,244), (3,244,244)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
